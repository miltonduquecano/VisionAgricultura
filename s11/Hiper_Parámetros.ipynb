{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2yl10IjmWap",
        "outputId": "20fb47ca-5f3a-468d-f2e3-8bcfdfd2a5c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3tkayIgmp4X",
        "outputId": "60b697e0-27a5-49a4-84da-8b486fae35d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.1-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/107.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-24.4.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-24.4.0 scikit-optimize-0.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from skopt import gp_minimize\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEYD96UlmbuI",
        "outputId": "9bb2140e-c35f-4c86-cc92-19c9d6b9626b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-318cc7f80aa0>:12: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner.tuners import RandomSearch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorio donde se encuentran las imágenes originales\n",
        "original_dir = '/content/drive/MyDrive/s11/Lemon_quality'\n",
        "\n",
        "# Directorio donde se almacenarán las imágenes divididas en conjuntos de entrenamiento, validación y prueba\n",
        "base_dir = '/content/drive/MyDrive/s11/Lemon_quality_dataset'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directorios para las categorías de limones\n",
        "categories = ['good_quality', 'bad_quality']\n"
      ],
      "metadata": {
        "id": "VWIXKMedoTpq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OKDPFA6sdP4M"
      },
      "outputs": [],
      "source": [
        "# Crear directorios para entrenamiento, validación y prueba\n",
        "for category in categories:\n",
        "    os.makedirs(os.path.join(base_dir, 'train', category), exist_ok=True)\n",
        "    os.makedirs(os.path.join(base_dir, 'validation', category), exist_ok=True)\n",
        "    os.makedirs(os.path.join(base_dir, 'test', category), exist_ok=True)\n",
        "\n",
        "# Copiar imágenes a los directorios correspondientes\n",
        "for category in categories:\n",
        "    category_dir = os.path.join(original_dir, category)\n",
        "    file_list = os.listdir(category_dir)\n",
        "\n",
        "    # Dividir las imágenes en conjuntos de entrenamiento (80%), validación (10%) y prueba (10%)\n",
        "    train_files, test_files = train_test_split(file_list, test_size=0.2, random_state=42)\n",
        "    valid_files, test_files = train_test_split(test_files, test_size=0.5, random_state=42)\n",
        "\n",
        "    # Copiar archivos a los directorios correspondientes\n",
        "    for file_name in train_files:\n",
        "        src = os.path.join(category_dir, file_name)\n",
        "        dst = os.path.join(base_dir, 'train', category, file_name)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    for file_name in valid_files:\n",
        "        src = os.path.join(category_dir, file_name)\n",
        "        dst = os.path.join(base_dir, 'validation', category, file_name)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    for file_name in test_files:\n",
        "        src = os.path.join(category_dir, file_name)\n",
        "        dst = os.path.join(base_dir, 'test', category, file_name)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "# Imprimir la cantidad de imágenes en cada conjunto\n",
        "for split in ['train', 'validation', 'test']:\n",
        "    for category in categories:\n",
        "        category_dir = os.path.join(base_dir, split, category)\n",
        "        print(f\"{split} {category} images: {len(os.listdir(category_dir))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "def load_image(file_path):\n",
        "    try:\n",
        "        img = Image.open(file_path)\n",
        "        img.load()\n",
        "        return img\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def remove_invalid_images(directory):\n",
        "    invalid_images = []\n",
        "    # Recorre todas las imágenes en el directorio\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            # Intenta cargar la imagen\n",
        "            img = load_image(file_path)\n",
        "            # Si la imagen no se puede abrir o no existe, la agregamos a la lista de imágenes inválidas\n",
        "            if img is None:\n",
        "                invalid_images.append(file_path)\n",
        "\n",
        "    # Elimina las imágenes inválidas\n",
        "    for file_path in invalid_images:\n",
        "        os.remove(file_path)\n",
        "        print(f\"Imagen eliminada: {file_path}\")\n"
      ],
      "metadata": {
        "id": "n36Y44aQwxIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorio donde se encuentran las imágenes\n",
        "train_dir = '/content/drive/MyDrive/s11/Lemon_quality_dataset/train'\n",
        "test_dir = '/content/drive/MyDrive/s11/Lemon_quality_dataset/test'\n",
        "validation_dir = '/content/drive/MyDrive/s11/Lemon_quality_dataset/validation'\n",
        "\n",
        "# Elimina las imágenes inválidas del directorio de entrenamiento\n",
        "remove_invalid_images(train_dir)\n",
        "remove_invalid_images(test_dir)\n",
        "remove_invalid_images(validation_dir)\n"
      ],
      "metadata": {
        "id": "asH6rxQrwx9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorios de los conjuntos de datos\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "valid_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# Configuración del generador de imágenes\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Generadores de imágenes\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aUf6GRfk5H-",
        "outputId": "d7facd75-2535-47d6-d617-4a583449c08b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1892 images belonging to 2 classes.\n",
            "Found 297 images belonging to 2 classes.\n",
            "Found 306 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Directorio donde se encuentran las divisiones del conjunto de datos\n",
        "train_dir = '/content/drive/MyDrive/s11/Lemon_quality_dataset/train'\n",
        "valid_dir = '/content/drive/MyDrive/s11/Lemon_quality_dataset/validation'\n",
        "test_dir = '/content/drive/MyDrive/s11/Lemon_quality_dataset/test'\n",
        "\n",
        "# Ruta de la imagen eliminada\n",
        "deleted_image_path = '/content/drive/MyDrive/s11/Lemon_quality_dataset/train/bad_quality/bad_quality_119.jpg'\n",
        "\n",
        "# Función para verificar la presencia de la imagen en una carpeta\n",
        "def check_image_presence(directory, image_path):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        if image_path in files:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Verificar la presencia de la imagen eliminada en cada división del conjunto de datos\n",
        "train_image_present = check_image_presence(train_dir, deleted_image_path)\n",
        "valid_image_present = check_image_presence(valid_dir, deleted_image_path)\n",
        "test_image_present = check_image_presence(test_dir, deleted_image_path)\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(f\"La imagen eliminada está presente en el conjunto de entrenamiento: {train_image_present}\")\n",
        "print(f\"La imagen eliminada está presente en el conjunto de validación: {valid_image_present}\")\n",
        "print(f\"La imagen eliminada está presente en el conjunto de prueba: {test_image_present}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK8CQ_TrwVbr",
        "outputId": "fdb6cacb-0a8b-4ba2-c577-7b352893965b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La imagen eliminada está presente en el conjunto de entrenamiento: False\n",
            "La imagen eliminada está presente en el conjunto de validación: False\n",
            "La imagen eliminada está presente en el conjunto de prueba: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la estructura del modelo\n",
        "def build_model(hp):\n",
        "    model = Sequential([\n",
        "        Conv2D(hp.Int('conv1_filter', min_value=32, max_value=128, step=16), (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(hp.Int('conv2_filter', min_value=32, max_value=64, step=16), (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(hp.Int('conv3_filter', min_value=32, max_value=64, step=16), (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(hp.Int('dense_units', min_value=32, max_value=128, step=16), activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Definir el tuner para la optimización de hiperparámetros\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    directory='keras_tuner',\n",
        "    project_name='lemon_quality')\n",
        "\n",
        "# Ejecutar la búsqueda de hiperparámetros\n",
        "tuner.search(train_generator,\n",
        "             validation_data=valid_generator,\n",
        "             epochs=5,\n",
        "             verbose=1)\n",
        "\n",
        "# Obtener el mejor modelo\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Imprimir el resumen del mejor modelo\n",
        "best_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hHACjilkfaL",
        "outputId": "4a3043a8-1bcb-4a97-91e6-095657cfce0a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 01m 02s]\n",
            "val_accuracy: 0.9562289714813232\n",
            "\n",
            "Best val_accuracy So Far: 0.9797979593276978\n",
            "Total elapsed time: 00h 38m 31s\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 48)        13872     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 48)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 64)        27712     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 18496)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 48)                887856    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 49        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 930385 (3.55 MB)\n",
            "Trainable params: 930385 (3.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}